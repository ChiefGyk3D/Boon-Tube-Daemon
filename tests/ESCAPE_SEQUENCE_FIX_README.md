# Escape Sequence Fix for Social Media Posts

## Problem

Social media posts generated by the Gemini LLM were occasionally displaying with escaped newlines (`\n`) appearing as literal text instead of actual line breaks. This resulted in posts that looked like:

```
"ðŸŽ¬ New YouTube-Videos video!\n\nMy bot generates AI-powered Yo Mama jokes on command.#dev #coding #AI\n\nhttps://www.youtube.com/watch?v=IXmy5ukxLvA"
```

Instead of the properly formatted:

```
ðŸŽ¬ New YouTube-Videos video!

My bot generates AI-powered Yo Mama jokes on command.#dev #coding #AI

https://www.youtube.com/watch?v=IXmy5ukxLvA
```

## Root Cause

The Gemini LLM occasionally returns responses that contain literal escape sequences (`\n`, `\t`, `\r`) instead of the actual characters they represent. Sometimes the responses are also wrapped in quotes, making them look like Python string representations.

## Solution

Added post-processing logic in the `_generate_with_retry()` method in `boon_tube_daemon/llm/gemini.py` to:

1. Detect responses containing escaped newlines (`\n`)
2. Convert escape sequences to their actual characters:
   - `\n` â†’ newline
   - `\t` â†’ tab
   - `\r` â†’ carriage return
3. Remove quote wrappers (both single and double quotes)
4. Strip whitespace

This fix is applied to all LLM responses, ensuring consistency across all features:
- Enhanced notifications
- Summaries
- Hashtags
- Sentiment analysis
- Content filtering

## Testing

Three test files validate the fix:

### 1. `test_escape_sequence_fix.py`
Comprehensive unit tests for the escape sequence decoding logic:
- Tests various formats of escaped text
- Verifies quotes are removed correctly
- Ensures already-correct text is not modified
- Tests mixed escape sequences

### 2. `test_llm_escape_sequence_demo.py`
Demonstration script that:
- Shows the exact issue from the GitHub report
- Applies the fix
- Displays before/after comparison
- Validates all content is preserved

### 3. Running the Tests

```bash
# Run unit tests
python tests/test_escape_sequence_fix.py

# Run demonstration
python tests/test_llm_escape_sequence_demo.py
```

Both tests should pass with all checks green.

## Impact

This fix ensures that:
- âœ… All social media posts display with proper formatting
- âœ… Newlines appear correctly on all platforms (Discord, Matrix, Bluesky, Mastodon)
- âœ… No literal escape sequences appear in posts
- âœ… Content (emojis, hashtags, URLs) is preserved correctly
- âœ… The fix is applied consistently across all LLM-generated content

## Code Changes

- **Modified**: `boon_tube_daemon/llm/gemini.py`
  - Updated `_generate_with_retry()` method to decode escape sequences
- **Added**: `tests/test_escape_sequence_fix.py`
  - Comprehensive test suite
- **Added**: `tests/test_llm_escape_sequence_demo.py`
  - Visual demonstration of the fix

## Related Issues

- Original issue: https://social.chiefgyk3d.com/@chiefgyk3d/115685450915853193
- GitHub Issue: "Occasional issue with formatting on social media posts"
